{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1db9f3fa-43e3-4b02-bfb6-e9571614b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "# discussion of circular fingerprints: https://pubs.acs.org/doi/10.1021/ci100050t\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Load the Models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "#Load the Metrics:\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#Other fingerprint types to explore? \n",
    "#useful example: https://medium.com/@gurkamaldeol/predicting-environmental-carcinogens-with-logistic-regression-knn-gradient-boosting-and-7973f88eb8b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31dea7f2-73ea-4714-95f8-8c0e64d7ff2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clintox.csv',\n",
       " 'sol_del.csv',\n",
       " 'HIV.csv',\n",
       " 'bace.csv',\n",
       " 'tox21.csv',\n",
       " 'deepchem_Lipophilicity.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets=[i for i in os.listdir('data_cleaned') if i[-4:]=='.csv']\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b36a46d6-99e9-4235-81dc-2a35dd46be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map={\n",
    "    'HIV.csv': {'target':'HIV_active','structure':'smiles'},\n",
    "    'bace.csv':{'target':'active','structure':'mol'},\n",
    "    'tox21.csv':{'target':'NR-AhR','structure':'smiles'},\n",
    "    'clintox.csv':{'target':'CT_TOX','structure':'smiles'},\n",
    "    'sol_del.csv':{'target':'binned_sol','structure':'smiles'},\n",
    "    'deepchem_Lipophilicity.csv':{'target':'drug_like','structure':'smiles'}   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b8d3002-cd6f-48be-bca5-ba071b70d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:47:36] Explicit valence for atom # 0 N, 5, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:47:36] Can't kekulize mol.  Unkekulized atoms: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:47:37] Explicit valence for atom # 10 N, 4, is greater than permitted\n",
      "[09:47:37] Explicit valence for atom # 10 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983\n",
      "984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:47:37] Can't kekulize mol.  Unkekulized atoms: 4\n",
      "[09:47:37] Can't kekulize mol.  Unkekulized atoms: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219\n",
      "1220\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('data_cleaned/clintox.csv')\n",
    "#X=[generate_fingerprint(mol,2,1024) for mol in tqdm(df['smiles'])]\n",
    "for i in range (df.shape[0]):\n",
    "    try:\n",
    "        test=Chem.MolFromSmiles(df.iloc[i]['smiles'])\n",
    "        test\n",
    "        np.array(AllChem.GetMorganFingerprintAsBitVect(test,2,1024))\n",
    "    except:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b30d3d01-45aa-4be0-8a4e-2d588141feef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                           7\n",
       "smiles          [NH4][Pt]([NH4])(Cl)Cl\n",
       "FDA_APPROVED                         1\n",
       "CT_TOX                               0\n",
       "Name: 7, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('data_cleaned/clintox.csv')\n",
    "df.iloc[7] # This one breaks the code, added try/except to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "432b67c6-f690-4f5d-b2d8-53669cc4b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fingerprint(smiles,radius,bits):\n",
    "    try:\n",
    "        mol=Chem.MolFromSmiles(smiles)\n",
    "        fp=AllChem.GetMorganFingerprintAsBitVect(mol,radius,bits)\n",
    "        return(np.array(fp))\n",
    "    except:\n",
    "        print(f'{smiles} failed in RDkit')\n",
    "        return (np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30155930-9711-4cc4-bdc3-90c8b4309e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test this: \n",
    "generate_fingerprint('C=C=C',2,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59b2a8fe-e20f-4089-97ea-8c74c62f37ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:52:03] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:52:03] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>smiles</th>\n",
       "      <th>activity</th>\n",
       "      <th>HIV_active</th>\n",
       "      <th>fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             smiles activity  \\\n",
       "0           0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...       CI   \n",
       "1           1  C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...       CI   \n",
       "\n",
       "   HIV_active                                                 fp  \n",
       "0           0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1           0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a test case with HIV data:\n",
    "radius=2\n",
    "bits=1024\n",
    "df=pd.read_csv('data_cleaned/HIV.csv')\n",
    "df['fp']=df['smiles'].apply(lambda x: generate_fingerprint(x,radius,bits))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "356088e8-337f-46a1-90a7-8afb12c93c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a better way to build and store the FPs. This will let us then drop nan from the dataframe before splitting.\n",
    "X=df['fp'].to_list()\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0\n",
    "y=df['HIV_active'].to_list()\n",
    "np.random.seed(1)\n",
    "scoring = ['accuracy', 'f1','roc_auc','neg_log_loss']\n",
    "clf= LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000,verbose=False)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring, cv=5,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5e5340e6-1ed5-49cd-9700-0cc15341a00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.04954553, 3.86408782, 4.41342711, 4.25944853, 4.00979447]),\n",
       " 'score_time': array([0.11747479, 0.12709665, 0.11286521, 0.11294889, 0.11964917]),\n",
       " 'test_accuracy': array([0.95805981, 0.96584002, 0.96948328, 0.96522796, 0.96121581]),\n",
       " 'train_accuracy': array([0.97519832, 0.97398255, 0.97240289, 0.9741961 , 0.97422649]),\n",
       " 'test_f1': array([0.12658228, 0.26246719, 0.37406484, 0.2955665 , 0.21621622]),\n",
       " 'train_f1': array([0.50724638, 0.465     , 0.42676768, 0.47753846, 0.48102815]),\n",
       " 'test_roc_auc': array([0.66082031, 0.76333741, 0.77115619, 0.74304506, 0.72269179]),\n",
       " 'train_roc_auc': array([0.91637289, 0.90556213, 0.90587435, 0.91068621, 0.90936153]),\n",
       " 'test_neg_log_loss': array([-0.1711814 , -0.13541844, -0.12954323, -0.14103344, -0.15442829]),\n",
       " 'train_neg_log_loss': array([-0.08519467, -0.09012307, -0.09160109, -0.0888303 , -0.08829654])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b987f35-8e48-4d9e-9789-a353412dd2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████▌         | 35081/41127 [00:35<00:07, 801.38it/s][15:54:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:54:16] WARNING: not removing hydrogen atom without neighbors\n",
      "100%|████████████████████████████████████████████████████████████████| 41127/41127 [00:42<00:00, 967.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# split the data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=[generate_fingerprint(mol,2,1024) for mol in tqdm(df['smiles'])]\n",
    "y=df['HIV_active'].to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e167455-8dd3-4514-8112-0e554d956ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#Load the Metrics:\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#RandomForestClassifier(max_depth=2, random_state=0)\n",
    "#KNeighborsClassifier(n_neighbors=5)\n",
    "#GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "#SVC(C=1.0, kernel='rbf', degree=3, gamma='scale',probability=True)\n",
    "\n",
    "\n",
    "# Setup Cross validation:\n",
    "scoring = ['accuracy', 'f1','roc_auc','neg_log_loss']\n",
    "clf= LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000,verbose=False)\n",
    "scores = cross_validate(clf, X_train, y_train, scoring=scoring, cv=5,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5198485-34a9-4a96-bab7-5feecf5e5cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.04000521, 2.9063077 , 3.0485034 , 3.0406611 , 3.4751327 ]),\n",
       " 'score_time': array([0.13809896, 0.09592152, 0.10188508, 0.10339856, 0.10300469]),\n",
       " 'test_accuracy': array([0.96887664, 0.96920084, 0.96839034, 0.96660723, 0.96660723]),\n",
       " 'train_accuracy': array([0.97442859, 0.97483385, 0.97479332, 0.97487437, 0.9747528 ]),\n",
       " 'test_f1': array([0.34693878, 0.37086093, 0.37299035, 0.33548387, 0.31333333]),\n",
       " 'train_f1': array([0.47980214, 0.49056604, 0.48595041, 0.49180328, 0.48976249]),\n",
       " 'test_roc_auc': array([0.784781  , 0.77769059, 0.79928654, 0.79040174, 0.7819159 ]),\n",
       " 'train_roc_auc': array([0.92498168, 0.92358746, 0.92086244, 0.9240289 , 0.92612064]),\n",
       " 'test_neg_log_loss': array([-0.12627385, -0.12951767, -0.12225941, -0.12971206, -0.13112323]),\n",
       " 'train_neg_log_loss': array([-0.08466068, -0.08375676, -0.08530655, -0.0841092 , -0.0839419 ])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa62f474-74d7-4ace-9204-aa0558005cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time 3.1021220207214357 +/- 0.19390261435995465\n",
      "score_time 0.10846176147460937 +/- 0.015061801418536861\n",
      "test_accuracy 0.9679364564759281 +/- 0.0011155552299617674\n",
      "train_accuracy 0.9747365861565893 +/- 0.0001592387964369198\n",
      "test_f1 0.3479214521322693 +/- 0.02239047288697682\n",
      "train_f1 0.487576872571201 +/- 0.0043512371238090255\n",
      "test_roc_auc 0.7868151541942294 +/- 0.007480604993680964\n",
      "train_roc_auc 0.923916223603868 +/- 0.001757327127758757\n",
      "test_neg_log_loss -0.12777724372882976 +/- 0.0031835495035589636\n",
      "train_neg_log_loss -0.08435502050890412 +/- 0.0005635325103984394\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(score,scores[score].mean(),'+/-',scores[score].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "022e97e5-d078-4b8e-82ef-555b1bfa549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_split(dataset,radius,bits):\n",
    "    df=pd.read_csv(os.path.join('data_cleaned',dataset))\n",
    "    \n",
    "    target=data_map[dataset]['target']\n",
    "    smiles=data_map[dataset]['structure']\n",
    "    \n",
    "    df['fp']=df[smiles].apply(lambda x: generate_fingerprint(x,radius,bits))\n",
    "    \n",
    "    df.dropna(subset=['fp',target],inplace=True) # remove any failed fingerprints\n",
    "    \n",
    "    X=df['fp'].to_list()\n",
    "    y=df[target].to_list()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\n",
    "    return(X_train,X_test,y_train,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a461cee6-1831-40b7-804f-78bd32e68fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Models:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#Load the Metrics:\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "scoring = ['accuracy', 'f1','roc_auc','neg_log_loss']\n",
    "\n",
    "models={'Logistic Regression':LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000,verbose=False),\n",
    "        'Random Forest':RandomForestClassifier(random_state=0,n_jobs=-1),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "        'Gradient Boosted Tree': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0),\n",
    "        'SVM':SVC(C=1.0, kernel='linear', degree=3, gamma='scale',probability=True),\n",
    "        'Dummy_Most_Frequent':DummyClassifier(strategy=\"most_frequent\")\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "458f3ac4-d50f-4b7b-a303-76ea42fa5acc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:52:51] WARNING: not removing hydrogen atom without neighbors\n",
      "[10:52:51] WARNING: not removing hydrogen atom without neighbors\n",
      "  0%|                                                                                 | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingLogistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▏                                                            | 1/6 [00:22<01:50, 22.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingRandom Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████▎                                                | 2/6 [02:08<04:45, 71.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingKNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████▌                                  | 3/6 [50:48<1:08:36, 1372.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingGradient Boosted Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████                        | 4/6 [55:13<31:10, 935.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████████████████████████▌           | 5/6 [2:18:51<40:07, 2407.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingDummy_Most_Frequent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 6/6 [2:18:51<00:00, 1388.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bace.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingLogistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▏                                                            | 1/6 [00:00<00:04,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingRandom Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████▎                                                | 2/6 [00:06<00:13,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingKNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████▌                                    | 3/6 [00:09<00:10,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingGradient Boosted Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████▋                        | 4/6 [00:12<00:06,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 6/6 [00:19<00:00,  3.27s/it]\n",
      "[13:12:10] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingDummy_Most_Frequent\n",
      "tox21.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingLogistic Regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     clf\u001b[38;5;241m=\u001b[39mmodels[model]\n\u001b[0;32m---> 11\u001b[0m     scores_dict\u001b[38;5;241m.\u001b[39mupdate({model : \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m})    \n\u001b[1;32m     12\u001b[0m dataset_results\u001b[38;5;241m.\u001b[39mupdate({dataset : scores_dict})\n",
      "File \u001b[0;32m~/miniconda3/envs/David/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:254\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m--> 254\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n\u001b[1;32m    257\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m scoring\n",
      "File \u001b[0;32m~/miniconda3/envs/David/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2316\u001b[0m, in \u001b[0;36mcheck_cv\u001b[0;34m(cv, y, classifier)\u001b[0m\n\u001b[1;32m   2311\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m cv\n\u001b[1;32m   2312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cv, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[1;32m   2313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2314\u001b[0m         classifier\n\u001b[1;32m   2315\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2316\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   2317\u001b[0m     ):\n\u001b[1;32m   2318\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m StratifiedKFold(cv)\n\u001b[1;32m   2319\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/David/lib/python3.9/site-packages/sklearn/utils/multiclass.py:332\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# check float and contains non-integer float values\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(y \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/David/lib/python3.9/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "dataset_results={}\n",
    "for dataset in data_map:\n",
    "    print(dataset)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = featurize_split(dataset,2,1024)\n",
    "    \n",
    "    scores_dict={}\n",
    "    for model in tqdm(models):\n",
    "        print(f'Training{model}')\n",
    "        clf=models[model]\n",
    "        scores_dict.update({model : cross_validate(clf, X_train, y_train, scoring=scoring, cv=5,return_train_score=True)})    \n",
    "    dataset_results.update({dataset : scores_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "107957cd-d395-45dd-8f05-6a2cb9ecc010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'fit_time': array([0.15550208, 0.13390923, 0.17209578, 0.14750457, 0.15982723]),\n",
       "  'score_time': array([0.00886178, 0.00786042, 0.00827837, 0.00608063, 0.00721574]),\n",
       "  'test_accuracy': array([0.79844961, 0.90272374, 0.85214008, 0.83268482, 0.86381323]),\n",
       "  'train_accuracy': array([0.9844358 , 0.97084548, 0.9776482 , 0.97959184, 0.97570457]),\n",
       "  'test_f1': array([0.85057471, 0.92877493, 0.89142857, 0.87679083, 0.89855072]),\n",
       "  'train_f1': array([0.98833819, 0.97835498, 0.9833454 , 0.98481562, 0.98194946]),\n",
       "  'test_roc_auc': array([0.86570443, 0.93393853, 0.93104855, 0.91918265, 0.92989256]),\n",
       "  'train_roc_auc': array([0.99803864, 0.99625912, 0.99609574, 0.99647131, 0.99568834]),\n",
       "  'test_neg_log_loss': array([-0.47948117, -0.30109057, -0.31976808, -0.34622067, -0.31200292]),\n",
       "  'train_neg_log_loss': array([-0.10125601, -0.1217003 , -0.12002358, -0.11479661, -0.12155927])},\n",
       " 'Random Forest': {'fit_time': array([3.06061268, 0.19523048, 0.26188326, 0.23659992, 0.24536777]),\n",
       "  'score_time': array([0.12815905, 0.11387825, 0.11654997, 0.09074664, 0.17187715]),\n",
       "  'test_accuracy': array([0.81395349, 0.88715953, 0.85603113, 0.84435798, 0.85992218]),\n",
       "  'train_accuracy': array([0.99513619, 0.99319728, 0.9941691 , 0.9941691 , 0.99319728]),\n",
       "  'test_f1': array([0.86516854, 0.91737892, 0.89458689, 0.88700565, 0.89830508]),\n",
       "  'train_f1': array([0.99635303, 0.99490168, 0.99562044, 0.99563319, 0.99490168]),\n",
       "  'test_roc_auc': array([0.86364251, 0.91802666, 0.91479668, 0.91136271, 0.91887665]),\n",
       "  'train_roc_auc': array([0.99994688, 0.99989603, 0.99992361, 0.99985783, 0.99984722]),\n",
       "  'test_neg_log_loss': array([-0.5428754 , -0.33168864, -0.45414142, -0.3510227 , -0.33087446]),\n",
       "  'train_neg_log_loss': array([-0.08950242, -0.09852958, -0.09520079, -0.09578862, -0.09992721])},\n",
       " 'KNN': {'fit_time': array([0.00560236, 0.00432992, 0.01989746, 0.00382376, 0.00513864]),\n",
       "  'score_time': array([0.28557539, 0.2235117 , 0.25883245, 0.27437735, 0.25476885]),\n",
       "  'test_accuracy': array([0.80232558, 0.85992218, 0.83657588, 0.84046693, 0.83268482]),\n",
       "  'train_accuracy': array([0.90272374, 0.89212828, 0.89601555, 0.90379009, 0.88726919]),\n",
       "  'test_f1': array([0.85217391, 0.89655172, 0.88268156, 0.88184438, 0.87608069]),\n",
       "  'train_f1': array([0.92836676, 0.92110874, 0.92427459, 0.92943692, 0.91784703]),\n",
       "  'test_roc_auc': array([0.8502569 , 0.8999388 , 0.89915681, 0.9119407 , 0.91418469]),\n",
       "  'train_roc_auc': array([0.96770026, 0.9616173 , 0.96332329, 0.96432057, 0.95714437]),\n",
       "  'test_neg_log_loss': array([-1.52037848, -1.05598132, -1.18930551, -0.8072789 , -0.67876183]),\n",
       "  'train_neg_log_loss': array([-0.20347586, -0.22078297, -0.21650891, -0.21737759, -0.23178218])},\n",
       " 'Gradient Boosted Tree': {'fit_time': array([0.61550689, 0.47260046, 0.45188165, 0.45205307, 0.44806957]),\n",
       "  'score_time': array([0.00739622, 0.00628591, 0.00619078, 0.00648928, 0.00620341]),\n",
       "  'test_accuracy': array([0.75968992, 0.79766537, 0.81712062, 0.79377432, 0.84046693]),\n",
       "  'train_accuracy': array([0.83171206, 0.81535471, 0.81146744, 0.82507289, 0.80855199]),\n",
       "  'test_f1': array([0.83854167, 0.86170213, 0.87598945, 0.8616188 , 0.88948787]),\n",
       "  'train_f1': array([0.88458973, 0.87299465, 0.87270341, 0.88047809, 0.87182824]),\n",
       "  'test_roc_auc': array([0.81540698, 0.86753706, 0.88664491, 0.8622331 , 0.90473276]),\n",
       "  'train_roc_auc': array([0.90380414, 0.89118995, 0.89356221, 0.89287897, 0.8914085 ]),\n",
       "  'test_neg_log_loss': array([-0.49699335, -0.45703893, -0.44445941, -0.4752966 , -0.43571396]),\n",
       "  'train_neg_log_loss': array([-0.42552857, -0.44132735, -0.44487448, -0.43610851, -0.44759487])},\n",
       " 'SVM': {'fit_time': array([0.8469677 , 1.1395812 , 0.98726034, 0.89331317, 1.38181925]),\n",
       "  'score_time': array([0.06379199, 0.06835938, 0.07448649, 0.07195449, 0.08455777]),\n",
       "  'test_accuracy': array([0.80232558, 0.89494163, 0.82879377, 0.84046693, 0.82879377]),\n",
       "  'train_accuracy': array([0.99124514, 0.98931001, 0.98931001, 0.98736638, 0.98833819]),\n",
       "  'test_f1': array([0.85131195, 0.92082111, 0.87356322, 0.88046647, 0.87134503]),\n",
       "  'train_f1': array([0.99342586, 0.99201162, 0.99201162, 0.99057288, 0.99127907]),\n",
       "  'test_roc_auc': array([0.85671309, 0.90497076, 0.90983272, 0.89069087, 0.89290086]),\n",
       "  'train_roc_auc': array([0.9973034 , 0.9930466 , 0.99443643, 0.99532974, 0.99515362]),\n",
       "  'test_neg_log_loss': array([-0.47516922, -0.34780509, -0.35945921, -0.39880371, -0.37494402]),\n",
       "  'train_neg_log_loss': array([-0.15898664, -0.18955348, -0.20569331, -0.18513887, -0.1770153 ])},\n",
       " 'Dummy_Most_Frequent': {'fit_time': array([0.00074887, 0.00073791, 0.00053144, 0.00053501, 0.00052714]),\n",
       "  'score_time': array([0.00399184, 0.0033257 , 0.003407  , 0.00331497, 0.00332236]),\n",
       "  'test_accuracy': array([0.66666667, 0.66536965, 0.66536965, 0.66536965, 0.66536965]),\n",
       "  'train_accuracy': array([0.66536965, 0.66569485, 0.66569485, 0.66569485, 0.66569485]),\n",
       "  'test_f1': array([0.8       , 0.79906542, 0.79906542, 0.79906542, 0.79906542]),\n",
       "  'train_f1': array([0.79906542, 0.79929988, 0.79929988, 0.79929988, 0.79929988]),\n",
       "  'test_roc_auc': array([0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "  'train_roc_auc': array([0.5, 0.5, 0.5, 0.5, 0.5]),\n",
       "  'test_neg_log_loss': array([-11.513192  , -11.55799041, -11.55799041, -11.55799041,\n",
       "         -11.55799041]),\n",
       "  'train_neg_log_loss': array([-11.55799041, -11.54675815, -11.54675815, -11.54675815,\n",
       "         -11.54675815])}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_results['bace.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1198ef1-ce6c-4055-b648-a0c3656b50fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingLogistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▌                                                          | 1/5 [00:18<01:13, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingRandom Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████▏                                           | 2/5 [00:32<00:47, 15.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingKNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████▏                            | 3/5 [07:44<06:51, 205.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingGradient Boosted Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████▌              | 4/5 [11:41<03:38, 218.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 5/5 [1:40:14<00:00, 1202.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Example for HIV:\n",
    "scores_dict={}\n",
    "for model in tqdm(models):\n",
    "    print(f'Training{model}')\n",
    "    clf=models[model]\n",
    "    scores_dict.update({model : cross_validate(clf, X_train, y_train, scoring=scoring, cv=5,return_train_score=True)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "650c49b2-29c1-4e2c-9385-877e71e241e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'fit_time': array([2.87739778, 3.22573662, 2.98598957, 3.13190079, 3.74218917]),\n",
       "  'score_time': array([0.097754  , 0.10137129, 0.12909412, 0.10858965, 0.12678814]),\n",
       "  'test_accuracy': array([0.96887664, 0.96920084, 0.96839034, 0.96660723, 0.96660723]),\n",
       "  'train_accuracy': array([0.97442859, 0.97483385, 0.97479332, 0.97487437, 0.9747528 ]),\n",
       "  'test_f1': array([0.34693878, 0.37086093, 0.37299035, 0.33548387, 0.31333333]),\n",
       "  'train_f1': array([0.47980214, 0.49056604, 0.48595041, 0.49180328, 0.48976249]),\n",
       "  'test_roc_auc': array([0.784781  , 0.77769059, 0.79928654, 0.79040174, 0.7819159 ]),\n",
       "  'train_roc_auc': array([0.92498168, 0.92358746, 0.92086244, 0.9240289 , 0.92612064]),\n",
       "  'test_neg_log_loss': array([-0.12627385, -0.12951767, -0.12225941, -0.12971206, -0.13112323]),\n",
       "  'train_neg_log_loss': array([-0.08466068, -0.08375676, -0.08530655, -0.0841092 , -0.0839419 ])},\n",
       " 'Random Forest': {'fit_time': array([2.10604024, 2.17551517, 2.13161039, 2.16317821, 2.15692306]),\n",
       "  'score_time': array([0.12280726, 0.15934086, 0.11789751, 0.13085651, 0.13718867]),\n",
       "  'test_accuracy': array([0.96514832, 0.96514832, 0.96498622, 0.96498622, 0.96498622]),\n",
       "  'train_accuracy': array([0.96502675, 0.96502675, 0.96506727, 0.96506727, 0.96506727]),\n",
       "  'test_f1': array([0., 0., 0., 0., 0.]),\n",
       "  'train_f1': array([0., 0., 0., 0., 0.]),\n",
       "  'test_roc_auc': array([0.75242089, 0.72141457, 0.73046348, 0.70194416, 0.68709832]),\n",
       "  'train_roc_auc': array([0.73221004, 0.74724027, 0.73805239, 0.74080463, 0.74202167]),\n",
       "  'test_neg_log_loss': array([-0.14104863, -0.14074602, -0.14051308, -0.14209739, -0.14199767]),\n",
       "  'train_neg_log_loss': array([-0.14097265, -0.14025793, -0.14075867, -0.1402306 , -0.14017537])},\n",
       " 'KNN': {'fit_time': array([0.0690825 , 0.06623006, 0.06295323, 0.06440377, 0.06482172]),\n",
       "  'score_time': array([22.0323379 , 17.28761339, 15.44206977, 16.69029951, 18.37838101]),\n",
       "  'test_accuracy': array([0.97471227, 0.97098395, 0.96920084, 0.97065975, 0.97163236]),\n",
       "  'train_accuracy': array([0.97552278, 0.97576593, 0.97677906, 0.9760496 , 0.9763738 ]),\n",
       "  'test_f1': array([0.51851852, 0.49002849, 0.40625   , 0.45970149, 0.4648318 ]),\n",
       "  'train_f1': array([0.53963415, 0.55505952, 0.56425856, 0.56766642, 0.56910569]),\n",
       "  'test_roc_auc': array([0.80807001, 0.76234269, 0.79556409, 0.75664114, 0.78157605]),\n",
       "  'train_roc_auc': array([0.97963025, 0.98007277, 0.97951065, 0.97960972, 0.98025333]),\n",
       "  'test_neg_log_loss': array([-0.45634582, -0.56856146, -0.49922526, -0.5916455 , -0.53012412]),\n",
       "  'train_neg_log_loss': array([-0.05485815, -0.05452291, -0.05397943, -0.05459601, -0.05411831])},\n",
       " 'Gradient Boosted Tree': {'fit_time': array([46.95861053, 47.67455053, 47.51688147, 46.26439953, 46.35894537]),\n",
       "  'score_time': array([0.13197589, 0.11823297, 0.10261345, 0.10828328, 0.11194849]),\n",
       "  'test_accuracy': array([0.96628303, 0.96644513, 0.96693143, 0.96676933, 0.96595883]),\n",
       "  'train_accuracy': array([0.9665667 , 0.96689091, 0.96660723, 0.9665667 , 0.96685038]),\n",
       "  'test_f1': array([0.07142857, 0.1038961 , 0.12068966, 0.10480349, 0.07894737]),\n",
       "  'train_f1': array([0.09836066, 0.11866235, 0.10822511, 0.10617551, 0.11279826]),\n",
       "  'test_roc_auc': array([0.75025232, 0.71541899, 0.73627909, 0.71787801, 0.70158137]),\n",
       "  'train_roc_auc': array([0.74282794, 0.74885063, 0.74286241, 0.7507581 , 0.75054755]),\n",
       "  'test_neg_log_loss': array([-0.1280068 , -0.13076759, -0.12720886, -0.13182317, -0.13126469]),\n",
       "  'train_neg_log_loss': array([-0.12826218, -0.12736458, -0.12857638, -0.12714202, -0.1270377 ])},\n",
       " 'SVM': {'fit_time': array([ 507.43349743,  538.41339326,  812.90487838,  517.20181131,\n",
       "         2222.17545128]),\n",
       "  'score_time': array([23.69892693, 33.90911031, 48.28376031, 19.75456476, 33.66022992]),\n",
       "  'test_accuracy': array([0.96936294, 0.96952504, 0.97017345, 0.96806614, 0.96855244]),\n",
       "  'train_accuracy': array([0.97414492, 0.975077  , 0.97463122, 0.97479332, 0.97438807]),\n",
       "  'test_f1': array([0.33684211, 0.38157895, 0.35664336, 0.34113712, 0.30714286]),\n",
       "  'train_f1': array([0.45283019, 0.48962656, 0.46034483, 0.47993311, 0.4532872 ]),\n",
       "  'test_roc_auc': array([0.76512175, 0.76652124, 0.76370613, 0.76954702, 0.76724776]),\n",
       "  'train_roc_auc': array([0.88289282, 0.88682516, 0.8788396 , 0.8830694 , 0.88517366]),\n",
       "  'test_neg_log_loss': array([-0.1226184 , -0.12222043, -0.12300755, -0.1239162 , -0.12497804]),\n",
       "  'train_neg_log_loss': array([-0.10562916, -0.10293233, -0.10466464, -0.10300151, -0.10351826])}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d27918e-7dec-4a2e-8815-e8bbea727634",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mscores_dict\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09e12428-cbc6-4ac6-810d-4efa331e521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "fit_time 3.19 +/- 0.3\n",
      "score_time 0.11 +/- 0.01\n",
      "test_accuracy 0.97 +/- 0.0\n",
      "train_accuracy 0.97 +/- 0.0\n",
      "test_f1 0.35 +/- 0.02\n",
      "train_f1 0.49 +/- 0.0\n",
      "test_roc_auc 0.79 +/- 0.01\n",
      "train_roc_auc 0.92 +/- 0.0\n",
      "test_neg_log_loss -0.13 +/- 0.0\n",
      "train_neg_log_loss -0.08 +/- 0.0\n",
      "Random Forest\n",
      "fit_time 2.15 +/- 0.02\n",
      "score_time 0.13 +/- 0.01\n",
      "test_accuracy 0.97 +/- 0.0\n",
      "train_accuracy 0.97 +/- 0.0\n",
      "test_f1 0.0 +/- 0.0\n",
      "train_f1 0.0 +/- 0.0\n",
      "test_roc_auc 0.72 +/- 0.02\n",
      "train_roc_auc 0.74 +/- 0.0\n",
      "test_neg_log_loss -0.14 +/- 0.0\n",
      "train_neg_log_loss -0.14 +/- 0.0\n",
      "KNN\n",
      "fit_time 0.07 +/- 0.0\n",
      "score_time 17.97 +/- 2.24\n",
      "test_accuracy 0.97 +/- 0.0\n",
      "train_accuracy 0.98 +/- 0.0\n",
      "test_f1 0.47 +/- 0.04\n",
      "train_f1 0.56 +/- 0.01\n",
      "test_roc_auc 0.78 +/- 0.02\n",
      "train_roc_auc 0.98 +/- 0.0\n",
      "test_neg_log_loss -0.53 +/- 0.05\n",
      "train_neg_log_loss -0.05 +/- 0.0\n",
      "Gradient Boosted Tree\n",
      "fit_time 46.95 +/- 0.58\n",
      "score_time 0.11 +/- 0.01\n",
      "test_accuracy 0.97 +/- 0.0\n",
      "train_accuracy 0.97 +/- 0.0\n",
      "test_f1 0.1 +/- 0.02\n",
      "train_f1 0.11 +/- 0.01\n",
      "test_roc_auc 0.72 +/- 0.02\n",
      "train_roc_auc 0.75 +/- 0.0\n",
      "test_neg_log_loss -0.13 +/- 0.0\n",
      "train_neg_log_loss -0.13 +/- 0.0\n",
      "SVM\n",
      "fit_time 919.63 +/- 661.09\n",
      "score_time 31.86 +/- 9.9\n",
      "test_accuracy 0.97 +/- 0.0\n",
      "train_accuracy 0.97 +/- 0.0\n",
      "test_f1 0.34 +/- 0.02\n",
      "train_f1 0.47 +/- 0.01\n",
      "test_roc_auc 0.77 +/- 0.0\n",
      "train_roc_auc 0.88 +/- 0.0\n",
      "test_neg_log_loss -0.12 +/- 0.0\n",
      "train_neg_log_loss -0.1 +/- 0.0\n"
     ]
    }
   ],
   "source": [
    "for key in scores_dict.keys():\n",
    "    print(key)\n",
    "    for score in scores_dict[key]:\n",
    "        print(score,scores_dict[key][score].mean().round(2),'+/-',scores_dict[key][score].std().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ccdb4a6a-dfa9-4be1-8fca-1a510857a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0,solver='lbfgs',max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "y_train_pred=clf.predict(X_train)\n",
    "y_test_pred=clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b05747c-7b6e-43bd-8a34-466f8d8bff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "result={}\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "result.update({'train':{'accuracy':accuracy_score(y_train, y_train_pred),\n",
    "                       'f1':f1_score(y_train, y_train_pred)}})\n",
    "\n",
    "result.update({'test':{'accuracy':accuracy_score(y_test, y_test_pred),\n",
    "                       'f1':f1_score(y_test, y_test_pred)}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23fc76e9-e148-47a8-997b-3d0b787c7e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'accuracy': 0.9735775652455827, 'f1': 0.45702864756828776},\n",
       " 'test': {'accuracy': 0.9693639369772418, 'f1': 0.3835616438356164}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Logistic Regression Result')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "728ec312-632b-4aef-8122-cb2f605cb9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'accuracy': 0.965051061760415, 'f1': 0.0},\n",
       " 'test': {'accuracy': 0.9645010698307722, 'f1': 0.0}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_train_pred=dummy_clf.predict(X_train)\n",
    "y_test_pred=dummy_clf.predict(X_test)\n",
    "\n",
    "result_dummy={}\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "result_dummy.update({'train':{'accuracy':accuracy_score(y_train, y_train_pred),\n",
    "                       'f1':f1_score(y_train, y_train_pred)}})\n",
    "\n",
    "result_dummy.update({'test':{'accuracy':accuracy_score(y_test, y_test_pred),\n",
    "                       'f1':f1_score(y_test, y_test_pred)}})\n",
    "print('Dummy Result')\n",
    "result_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "56dbcf94-4ec3-44bb-a11e-def22cee2512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39684\n",
       "1     1443\n",
       "Name: HIV_active, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HIV_active'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e1dc09c-e773-4329-ac02-a3cb8d7444f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.964914\n",
       "1    0.035086\n",
       "Name: HIV_active, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HIV_active'].value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c3143-1bc1-41dc-918b-12e4c25756d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the model\n",
    "with open('model_pkl', 'wb') as files:\n",
    "    pickle.dump(model, files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c4f4359cbd00efd9da0914ac51ba55447235b2a8439e4bf567804ab1066f578"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
